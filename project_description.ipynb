{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Image Stitcher\n",
    "## Assigned: 02.01.2019\n",
    "## Due Date: TBD (probably 02.20.2019)\n",
    "\n",
    "Panoramic photography is ubiquitous, with nearly every digital camera having a mode dedicated to doing it.  Here's an example from the Italian Alps:\n",
    "<img src=\"pano.jpg\">\n",
    "Note the extreme aspect ratio: much larger than the 4:3 or 3:2 that is typical of most cameras; suffice to say, the camera that stook this picture did not have a sensor that was this wide.  So how are these things made?  Stated simply, multiple images are taken, mutually identifiable points are located in each of these images, and the images are warped such that these points are coincident.  The matching stage might look like this:\n",
    "<img src=\"office.jpeg\">\n",
    "\n",
    "For this project, you will code your own image stitcher from scratch.  Despite the conceptual simplicity of this operation, there are a surprising number of challenges that need to be addressed.  A general framework for a stitcher might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cornermatching as cm\n",
    "import skimage.transform as skt\n",
    "\n",
    "class Stitcher(object):\n",
    "    def __init__(self,image_1,image_2):\n",
    "        self.images = [image_1,image_2]\n",
    "        \n",
    "    def find_keypoints(self):\n",
    "        \n",
    "        # Guass kernel for convolution\n",
    "        g_kernal = cm.gauss_kernal(5,2)\n",
    "        \n",
    "        # Calculate the harris response of each convolution of I1, I2\n",
    "        H1 = cm.harris_response(cm.convolve(self.images[0], g_kernal))\n",
    "        H2 = cm.harris_response(cm.convolve(self.images[1], g_kernal))\n",
    "        \n",
    "        # Extract the keypoints from H1, H2 via non-maximal sup\n",
    "        key_pts_I1 = cm.nonmaxsup(H1)\n",
    "        key_pts_I2 = cm.nonmaxsup(H2)\n",
    "        \n",
    "        # Return the keypoints of I1, I2\n",
    "        return key_pts_I1, key_pts_I2\n",
    "    \n",
    "    def generate_descriptors(self):\n",
    "        \n",
    "        # Get the keypoints to generate descriptors from\n",
    "        key_pts_I1, key_pts_I2 = self.find_keypoints()\n",
    "        \n",
    "        # Get descriptors for I1, I2\n",
    "        des_I1 = cm.descriptorExtractor(self.images[0], key_pts_I1)\n",
    "        des_I2 = cm.descriptorExtractor(self.images[1], key_pts_I2)\n",
    "        \n",
    "        return des_I1, des_I2\n",
    "        \"\"\"\n",
    "        Step 2: After identifying relevant keypoints, we need to come up with a quantitative description of the \n",
    "        neighborhood of that keypoint, so that we can match it to keypoints in other images.\n",
    "        \"\"\"\n",
    "        \n",
    "    def match_keypoints(self):\n",
    "        \n",
    "        des_I1, des_I2 = self.generate_descriptors()\n",
    "        \n",
    "        best_matches = cm.get_best_matches(des_I1, des_I2)\n",
    "        secondbest_matches = cm.get_secondbest_matches(des_I1, des_I2, best_matches)\n",
    "        \n",
    "        \n",
    "        filtered_matches = cm.filter_matches(best_matches, secondbest_matches)\n",
    "        \n",
    "        return filtered_matches, des_I1\n",
    "    \n",
    "        \"\"\"\n",
    "        Step 3: Compare keypoint descriptions between images, identify potential matches, and filter likely\n",
    "        mismatches\n",
    "        \"\"\"\n",
    "        \n",
    "    def find_homography(self):\n",
    "        \n",
    "        # Get the matches between the two images\n",
    "        matches, des_I1 = self.match_keypoints()\n",
    "        \n",
    "        # Now get the coordinates from the matches for RANSAC\n",
    "        match_coords = []\n",
    "        for match in matches: #filtered_matches:\n",
    "    \n",
    "            match_I1_x = des_I1[match[0]][1]\n",
    "\n",
    "            match_I1_y = des_I1[match[0]][2]\n",
    "    \n",
    "            match_I2_x = match[1][1]\n",
    "    \n",
    "            match_I2_y = match[1][2]\n",
    "    \n",
    "            match_coords.append([match_I1_x,match_I1_y,match_I2_x,match_I2_y])\n",
    "        \n",
    "        # params needed for RANSAC\n",
    "        print(len(match_coords))\n",
    "        num_iters = 1000\n",
    "        r = 3\n",
    "        d = 4\n",
    "        n = int(len(matches)/2)\n",
    "        \n",
    "        H_best = cm.RANSAC(num_iters, match_coords, n, r, d)\n",
    "        \n",
    "        return H_best\n",
    "        \"\"\"\n",
    "        Step 4: Find a linear transformation (of various complexities) that maps pixels from the second image to \n",
    "        pixels in the first image\n",
    "        \"\"\"\n",
    "      \n",
    "    def stitch(self,H):\n",
    "        # Create a projective transform based on the homography matrix $H$\n",
    "        proj_trans = skt.ProjectiveTransform(H)\n",
    "        I1 = self.images[0]\n",
    "        I2 = self.images[1]\n",
    "        # Warp the image into image 1's coordinate system\n",
    "        image_2_transformed = skt.warp(I2,proj_trans)\n",
    "        I1 = I1 + image_2_transformed\n",
    "        print(image_2_transformed.shape)\n",
    "        plt.imshow(image_2_transformed, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        Step 5: Transform second image into local coordinate system of first image, and (perhaps) perform blending\n",
    "        to avoid obvious seams between images.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will populate these functions over the next several weeks, a process that will involve delving into some of the most elementary operations in digital signal processing.  \n",
    "\n",
    "As a test case, apply your stitcher to at least four overlapping images that you've taken.  With a stitcher that works on two images, more images can be added by applying the method recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#def stitchImages():\n",
    "'''Returns the stiched images recursively'''\n",
    "\n",
    "images = [plt.imread('im1.jpg').mean(axis=2), plt.imread('im2.jpg').mean(axis=2), plt.imread('im3.jpg').mean(axis=2), plt.imread('im4.jpg').mean(axis=2)]\n",
    "\n",
    "image_stitcher = Stitcher(images[0], images[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_matches, best_matches = image_stitcher.match_keypoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,inliers = image_stitcher.find_homography()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_stitcher.stitch(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "h = int(len(images[0]))\n",
    "w = int(len(images[0][0])*2)\n",
    "s = (h,w)\n",
    "print(s)\n",
    "new_image = np.zeros(s)\n",
    "new_image[0:h, 0:int(w/2)] = images[2]\n",
    "new_image[0:h, int(w/2):] = images[3]\n",
    "plt.imshow(new_image, cmap=\"gray\")\n",
    "\n",
    "for match in filtered_matches:\n",
    "    x1 = best_matches[match[0]][1]\n",
    "    y1 = best_matches[match[0]][2]\n",
    "    x2 = match[1][1]\n",
    "    y2 = match[1][2]\n",
    "    print(x1,y1,x2,y2)\n",
    "    plt.plot([y1,y2+int(w/2)], [x1,x2], color=\"blue\", marker=\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
